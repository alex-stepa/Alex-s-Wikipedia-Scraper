**Alex’s Wikipedia Scraper**

Alex’s Wikipedia Scraper is a Python script that automatically downloads random English Wikipedia articles. It saves the content in a structured format, including article text, images, tables, media files (like PDFs or MP3s), references, and external links. The script also keeps a log of downloaded articles to avoid duplicates, making it perfect for research, data collection, or offline reading.

Features
	•	Downloads random English Wikipedia articles indefinitely.
	•	Saves article text in .txt format with sections and headings.
	•	Downloads all images in the article.
	•	Saves tables as CSV files.
	•	Downloads linked media files (PDF, MP3, etc.).
	•	Saves references and external links in separate text files.
	•	Keeps a CSV log to avoid downloading the same article twice.

**Usage**
  
install

https://github.com/alex-stepa/Alex-s-Wikipedia-Scraper

install dependencies

pip install requests beautifulsoup4

Thanks for installing and enjoy ;3
